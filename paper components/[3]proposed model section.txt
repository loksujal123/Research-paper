3. Proposed Ensemble Method
This section details our proposed ensemble approach for image classification, aiming to surpass the state-of-the-art accuracy on the X-ray image dataset. The proposed method leverages a weighted ensemble strategy, leveraging the strengths of individual deep learning models [add figure link here (figure 1)].

3.1 Base Learner Selection
The effectiveness of an ensemble hinges on the selection of its base learners. We meticulously selected five state-of-the-art convolutional neural network (CNN) architectures as base learners, renowned for their performance in image classification tasks. These architectures include:

-ResNet []
-IceptionV3 []
-MbileNetV2 []
-NasNet[] 
-Xception []

[add links here too]

Each of these models possesses a unique architectural design, leading to diverse capabilities in generalizing across the provided dataset distribution.

3.2 Model Training and Weight Factor Calculation
Following base learner selection, we individually train each model on the training set. Their corresponding validation accuracies (acc_j) are meticulously recorded using a separate validation set (important to note: this validation set is not used during the training process). Since each model has distinct hyperparameters, they learn the underlying distribution with varying degrees of success.

OR

{
After selecting the base learners, we trained each model individually on the training dataset. A separate validation set was used to assess their performance, resulting in recorded validation accuracies (acc_j). Due to the diverse hyperparameters employed by each model, they learned the underlying data distribution in distinct ways.
}

Once trained, the models are evaluated on the validation set, generating their individual accuracies (acc_j). These recorded accuracies are then employed to calculate the weight factor (α_j) for each model using Equations (1) and (2). Here, j ranges from 1 to m, where m represents the total number of base learners in the ensemble.

Equation (1) incorporates a parameter β to prevent models with very low accuracy from dominating the ensemble's final prediction. We set β to a small positive value (e.g., 0.01). Equation (2) finds the minimum accuracy (min_acc) amongst all base learners.

Equations:

α_j = acc_j - β + 1 (Equation 1)
min_acc = min(acc_j) (for j = 1 to m) (Equation 2)

3.3 Ensemble Aggregation of Models
The trained models collaborate to make a final prediction for a given input sample. After the softmax function is applied to each model's output, a probability vector (C_k) is obtained for each input sample T_i. Here, k ranges from 1 to nc, where nc represents the total number of classes present in the dataset.   

The output of each model ([M_j]) is then multiplied by its corresponding weight factor (α_j). Subsequently, for each class, the weighted probabilities are summed together, generating the ensemble model's final output for that particular class (Equation 3). This process is further illustrated in Algorithm 1.   

Equation:

OutputClass_T_i,ensemble = max(∑_(j=1)^m (α_j * [C_k]_i,j)) (for k = 1 to nc) (Equation 3)

3.4 Implementation Details (Algorithm 1)
Algorithm 1 outlines the step-by-step process for the proposed weighted ensemble model (WEM). As described in the algorithm, we prepare the dataset and partition it into training, validation, and testing sets.

The training data (D) is loaded, comprising feature vectors (x_h) and corresponding labels (y_h). A portion of the dataset is used for validation and loaded into set V. Finally, the remaining data is utilized for testing and loaded into set T.

Following the selection of m base learners, each model is individually trained on the training dataset D (in your case, m = 5). After training, each model generates predictions on the validation set data ([V_i] for i = 1 to g). These predictions are employed to calculate the accuracy of each model (M_j).

Next, the parameter min_acc is computed, which facilitates the calculation of the weight factor (α_j) for each model. These α_j values are then used as multipliers for the individual model predictions. The weighted predictions from all models are summed, forming the output of the proposed WEM.

To classify an input sample using the WEM's output, we employ the argmax function, which returns the class with the highest probability. Alternatively, the WEM's output can be fed into the softmax function to achieve the same result.   

Algorithm 1: Weighted Ensemble Model

Input:

Datasets:

D = {(x₁, y₁), ..., (x_h, y_h)}: Training dataset
V = {(x₁, y₁), ..., (x_g, y_g)}: Validation dataset
T = {(x₁, y₁), ..., (x_n, y_n)}: Testing dataset
Base Learners:

M_j: j-th model, where j = 1, ..., m
nc: Number of classes
Output:

Predicted class labels for the testing dataset
Steps:

Initialize:

Set β to a small positive value (e.g., 0.01).
Initialize weight factors α_j for each model.
Train Base Learners:

Train each model M_j on the training dataset D.
Evaluate on Validation Set:

Use each model M_j to predict labels for the validation dataset V.
Calculate the accuracy acc_j for each model.
Calculate Weight Factors:

Compute min_acc = min(acc_j) for j = 1 to m.
Calculate α_j = acc_j - β + 1 for j = 1 to m.
Ensemble Prediction:

For each input sample x_i in the testing dataset T:
Obtain predictions from each model M_j for x_i.
Apply the softmax function to normalize the predicted probabilities.
Calculate the weighted sum of predictions: predicted_class = argmax(∑_(j=1)^m (α_j * predicted_probs_j)).
Return:

Return the predicted class labels for the testing dataset.


3.4 Implementation Details

To evaluate the performance of our proposed weighted ensemble model, we conducted experiments on a publicly available X-ray image dataset [Dataset Link]. This dataset comprises images categorized into pneumonia, COVID-19, and no-findings classes, aligning with current healthcare priorities.

Given the computational demands and potential for overfitting associated with training large-scale models from scratch, we adopted a transfer learning strategy. The five selected classification models (ResNet101, Inception, MobileNetV2, NasNet, and Xception) were initialized with pre-trained weights from the ImageNet dataset.

To adapt these models to the specific characteristics of the medical imaging dataset, we fine-tuned them for 15 epochs using the Adam optimizer with a learning rate of 0.001. This fine-tuning process involved adjusting the model parameters to improve their performance on the target classification task.

Key Points:

Dataset Selection: The chosen dataset is relevant to current healthcare challenges and provides a diverse representation of X-ray images.
Transfer Learning: Leveraging pre-trained models from ImageNet accelerates the training process and improves generalization.
Hyperparameter Tuning: We maintained the original hyperparameters of the base models, focusing on the fine-tuning process to adapt them to the medical imaging domain.
Epochs: 15 epochs were deemed sufficient for effective fine-tuning while balancing computational resources.
Optimizer and Learning Rate: The Adam optimizer with a learning rate of 0.001 was selected based on its efficiency and stability in training deep neural networks.
By adopting this approach, we were able to effectively train the base learners on the medical imaging dataset, setting the stage for the ensemble aggregation process.
